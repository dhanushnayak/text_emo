{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextEmotion",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHyBxndmBLIKDPH+cBKFcf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhanushnayak/text_emo/blob/main/TextEmotion_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogvcxqT417Wi"
      },
      "source": [
        "#import libaries\n",
        "!pip install neattext\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import neattext.functions as nt \n",
        "plt.style.use(\"ggplot\")\n",
        "plt.rcParams[\"figure.figsize\"] = (16,5)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ShDUwmg2BpX"
      },
      "source": [
        "#reading_csv\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Jcharis/end2end-nlp-project/main/notebooks/data/emotion_dataset_raw.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYtlWsSK2Cb2"
      },
      "source": [
        "df['clean_text']=df[\"Text\"].apply(nt.remove_stopwords).apply(nt.remove_userhandles).apply(nt.remove_punctuations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLC6C4Xj20mt"
      },
      "source": [
        "#pip install tf-nightly-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmCOQusU2pkN"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZWE8X5T2SD4"
      },
      "source": [
        "from tensorflow.keras.models import  Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense,LSTM ,Dropout, Embedding,Bidirectional,GlobalMaxPooling1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpuwNUL93WaQ"
      },
      "source": [
        "tok=Tokenizer()\n",
        "tok.fit_on_texts(df['clean_text'])\n",
        "seq = tok.texts_to_sequences(df['clean_text'])\n",
        "y = df['Emotion']\n",
        "onehot = OneHotEncoder().fit(y.values.reshape(-1,1))\n",
        "yone1 = onehot.transform(y.values.reshape(-1,1))\n",
        "yone1=yone1.toarray()\n",
        "post_pad = pad_sequences(seq, padding='pre',maxlen=256)\n",
        "voc_size = len(tok.word_index) + 1 # as it was started from 0\n",
        "x_train1,x_test1,y_train1,y_test1 = train_test_split(post_pad,yone1,test_size=0.3,random_state=42,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qsCSFSYE3rS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAVhBtIe3m8-"
      },
      "source": [
        "#del model\n",
        "model = Sequential()\n",
        "#model.add(Embedding(inp  , op , inp length))\n",
        "model.add(Embedding(voc_size , 1000 , input_length = 256,))\n",
        "model.add(Bidirectional(LSTM(100 , return_sequences = True)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Bidirectional(LSTM(50)))\n",
        "model.add(Dense(100 , activation= 'relu'))\n",
        "model.add(Dense(50 , activation= 'relu'))\n",
        "model.add(Dense(8 , activation = 'softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9MVlbhP4-S2"
      },
      "source": [
        "!pip install livelossplot==0.5.0\n",
        "import livelossplot\n",
        "#!pip install keras==2.3.1\n",
        "opt = tf.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_rate=0.98,decay_steps=5)\n",
        "adam = tf.optimizers.Adam(learning_rate=opt)\n",
        "sgd = tf.optimizers.SGD(learning_rate=opt)\n",
        "#model.compile(loss = 'categorical_crossentropy\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy' , optimizer = adam ,metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlh0KWkY5Vpk"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,EarlyStopping\n",
        "\n",
        "#from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "\n",
        "from livelossplot.inputs.tf_keras import PlotLossesCallback\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"model_weights_dhanush_text_emotion_256v1.h5\",monitor=\"val_accuracy\",save_weights_only=True,mode=\"max\",verbose=1)\n",
        "#reduce_lr = ReduceLROnPlateau(monitor='var_loss',factor=0.1,patience=2,min_lr=0.00001,model='auto')\n",
        "early_stop = EarlyStopping(monitor=\"val_accuracy\",patience=20,mode='max',min_delta=0)\n",
        "callbacks=[PlotLossesCallback(),checkpoint,early_stop]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTCdTaTM6ALz"
      },
      "source": [
        "\n",
        "history = model.fit(post_pad,yone1,validation_split=0.2,batch_size = 128 , epochs = 50 ,callbacks=callbacks) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wWKmY5swMMn"
      },
      "source": [
        "def predict(text):\n",
        "  from neattext import TextExtractor\n",
        "  sentx1 = TextExtractor(text=text)\n",
        "  text1=sentx1.remove_puncts().remove_stopwords().remove_userhandles().text\n",
        "  intok=tok.texts_to_sequences([text1])\n",
        "  seqin = pad_sequences(intok, padding='pre',maxlen=256)\n",
        "  a= model.predict([seqin])\n",
        "  return onehot.inverse_transform(a)\n",
        "predict('hello im anger on @dhanush')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzfT66iB40Mu"
      },
      "source": [
        "predict(\"im sorry\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcJYPFJxC8_6"
      },
      "source": [
        "text = 'what the hell dude @dhanush'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HdzmTpMBA1v"
      },
      "source": [
        "predict(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCVLDrQjFnEB"
      },
      "source": [
        "predict(\"i not liked it\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nj3whVAFx-p"
      },
      "source": [
        "predict(\"i not liked it, this are fake and undefined people, im realy sad\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYWmg15lGIAV"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('tokenizer_text_emotion.pickle', 'wb') as handle:\n",
        "    pickle.dump(tok, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTUZgqW9GiqS"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"Keras_model_for_text_emotion.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"Keras_model_for_text_emotion_weights.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyumN7F7HoVs"
      },
      "source": [
        "import joblib\n",
        "joblib.dump(onehot, 'onehot_encoder_text_emotion.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWavyb0PioQO"
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGRXPysWioiD"
      },
      "source": [
        "json_file = open('./model', 'r')\n",
        "\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model_num.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "loaded_model.save('model_num.hdf5')\n",
        "loaded_model=load_model('model_num.hdf5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygRGh-T0i_pi"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-zZdnohj85i"
      },
      "source": [
        "import numpy as np\n",
        "a = np.array([12])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JptGIgqkER4"
      },
      "source": [
        "np.save(\"arr.npy\",a)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}